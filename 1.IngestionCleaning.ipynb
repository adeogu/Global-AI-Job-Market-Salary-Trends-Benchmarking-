{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d6d3499",
   "metadata": {},
   "source": [
    "# Ingestion & Cleaning — USA Salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a8ba2559-58b5-4302-87bd-893178f23550",
   "metadata": {},
   "outputs": [],
   "source": [
    "##1.Setup and Ingestion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9a4d391c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import core data analysis libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', 200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "494e865f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of         job_id                    job_title  salary_usd salary_currency  \\\n",
       "0      AI00001        AI Research Scientist       90376             USD   \n",
       "1      AI00002         AI Software Engineer       61895             USD   \n",
       "2      AI00003                AI Specialist      152626             USD   \n",
       "3      AI00004                 NLP Engineer       80215             USD   \n",
       "4      AI00005                AI Consultant       54624             EUR   \n",
       "...        ...                          ...         ...             ...   \n",
       "14995  AI14996            Robotics Engineer       38604             USD   \n",
       "14996  AI14997  Machine Learning Researcher       57811             GBP   \n",
       "14997  AI14998                 NLP Engineer      189490             USD   \n",
       "14998  AI14999                   Head of AI       79461             EUR   \n",
       "14999  AI15000     Computer Vision Engineer       56481             USD   \n",
       "\n",
       "      experience_level employment_type company_location company_size  \\\n",
       "0                   SE              CT            China            M   \n",
       "1                   EN              CT           Canada            M   \n",
       "2                   MI              FL      Switzerland            L   \n",
       "3                   SE              FL            India            M   \n",
       "4                   EN              PT           France            S   \n",
       "...                ...             ...              ...          ...   \n",
       "14995               EN              FL          Finland            S   \n",
       "14996               EN              CT   United Kingdom            M   \n",
       "14997               EX              CT      South Korea            L   \n",
       "14998               EN              FT      Netherlands            M   \n",
       "14999               MI              PT          Austria            S   \n",
       "\n",
       "      employee_residence  remote_ratio  \\\n",
       "0                  China            50   \n",
       "1                Ireland           100   \n",
       "2            South Korea             0   \n",
       "3                  India            50   \n",
       "4              Singapore           100   \n",
       "...                  ...           ...   \n",
       "14995            Finland            50   \n",
       "14996     United Kingdom             0   \n",
       "14997        South Korea            50   \n",
       "14998        Netherlands             0   \n",
       "14999            Austria            50   \n",
       "\n",
       "                                       required_skills education_required  \\\n",
       "0             Tableau, PyTorch, Kubernetes, Linux, NLP           Bachelor   \n",
       "1      Deep Learning, AWS, Mathematics, Python, Docker             Master   \n",
       "2         Kubernetes, Deep Learning, Java, Hadoop, NLP          Associate   \n",
       "3                            Scala, SQL, Linux, Python                PhD   \n",
       "4                         MLOps, Java, Tableau, Python             Master   \n",
       "...                                                ...                ...   \n",
       "14995                          Java, Kubernetes, Azure           Bachelor   \n",
       "14996          Mathematics, Docker, SQL, Deep Learning             Master   \n",
       "14997                                Scala, Spark, NLP          Associate   \n",
       "14998        Java, Computer Vision, Python, TensorFlow                PhD   \n",
       "14999    Scala, Azure, Deep Learning, GCP, Mathematics                PhD   \n",
       "\n",
       "       years_experience       industry posting_date application_deadline  \\\n",
       "0                     9     Automotive   2024-10-18           2024-11-07   \n",
       "1                     1          Media   2024-11-20           2025-01-11   \n",
       "2                     2      Education   2025-03-18           2025-04-07   \n",
       "3                     7     Consulting   2024-12-23           2025-02-24   \n",
       "4                     0          Media   2025-04-15           2025-06-23   \n",
       "...                 ...            ...          ...                  ...   \n",
       "14995                 1         Energy   2025-02-06           2025-03-25   \n",
       "14996                 0     Government   2024-10-16           2024-10-30   \n",
       "14997                17  Manufacturing   2024-03-19           2024-05-02   \n",
       "14998                 1    Real Estate   2024-03-22           2024-04-23   \n",
       "14999                 2     Technology   2024-07-18           2024-08-10   \n",
       "\n",
       "       job_description_length  benefits_score       company_name  \n",
       "0                        1076             5.9    Smart Analytics  \n",
       "1                        1268             5.2       TechCorp Inc  \n",
       "2                        1974             9.4    Autonomous Tech  \n",
       "3                        1345             8.6     Future Systems  \n",
       "4                        1989             6.6  Advanced Robotics  \n",
       "...                       ...             ...                ...  \n",
       "14995                    1635             7.9  Advanced Robotics  \n",
       "14996                    1624             8.2    Smart Analytics  \n",
       "14997                    1336             7.4     AI Innovations  \n",
       "14998                    1935             5.6    Smart Analytics  \n",
       "14999                    2492             7.6     AI Innovations  \n",
       "\n",
       "[15000 rows x 19 columns]>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv('data/ai_job_dataset0.csv')\n",
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "37fc815f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initial DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15000 entries, 0 to 14999\n",
      "Data columns (total 19 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   job_id                  15000 non-null  object \n",
      " 1   job_title               15000 non-null  object \n",
      " 2   salary_usd              15000 non-null  int64  \n",
      " 3   salary_currency         15000 non-null  object \n",
      " 4   experience_level        15000 non-null  object \n",
      " 5   employment_type         15000 non-null  object \n",
      " 6   company_location        15000 non-null  object \n",
      " 7   company_size            15000 non-null  object \n",
      " 8   employee_residence      15000 non-null  object \n",
      " 9   remote_ratio            15000 non-null  int64  \n",
      " 10  required_skills         15000 non-null  object \n",
      " 11  education_required      15000 non-null  object \n",
      " 12  years_experience        15000 non-null  int64  \n",
      " 13  industry                15000 non-null  object \n",
      " 14  posting_date            15000 non-null  object \n",
      " 15  application_deadline    15000 non-null  object \n",
      " 16  job_description_length  15000 non-null  int64  \n",
      " 17  benefits_score          15000 non-null  float64\n",
      " 18  company_name            15000 non-null  object \n",
      "dtypes: float64(1), int64(4), object(14)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# Initial check: display info and missing values\n",
    "print(\"\\nInitial DataFrame Info:\")\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccdb5dc",
   "metadata": {},
   "source": [
    "### Quick schema check — align to proposal columns\n",
    "We expect the dataset to contain (per proposal):\n",
    "- job_id, job_title, salary_usd, salary_currency, salary_local, experience_level,\n",
    "- employment_type, job_category, company_location, company_size, employee_residence,\n",
    "- remote_ratio, required_skills, education_required, years_experience, industry,\n",
    "- posting_date, application_deadline, job_description_length, benefits_score\n",
    "\n",
    "We'll display the actual columns present and map / rename where needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9f1e23fd-5ad9-4e87-9386-e391eaa3b8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Column Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "08ecb181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Canonical columns:\n",
      " ['job_id', 'job_title', 'salary_usd', 'salary_currency', 'experience_level', 'employment_type', 'company_location', 'company_size', 'employee_residence', 'remote_ratio', 'required_skills', 'education_required', 'years_experience', 'industry', 'posting_date', 'application_deadline', 'job_description_length', 'benefits_score', 'company_name']\n"
     ]
    }
   ],
   "source": [
    "def canonicalize_columns(df_in):\n",
    "    \"\"\"Lowercases and standardizes column names.\"\"\"\n",
    "    df_out = df_in.copy()\n",
    "    col_map = {c: c.strip().lower().replace('-', '_').replace(' ', '_') for c in df_out.columns}\n",
    "    df_out = df_out.rename(columns=col_map)\n",
    "    return df_out\n",
    "\n",
    "df_cleaned = canonicalize_columns(df)\n",
    "print('Canonical columns:\\n', df_cleaned.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "542fef7a-1746-4cdb-aaa7-12afb21ff74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Dropping Unnecessary Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ccbec018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped columns: ['salary_currency']\n",
      "DataFrame shape after drops: (15000, 18)\n"
     ]
    }
   ],
   "source": [
    "# Define columns to drop as per your focus\n",
    "cols_to_drop = ['salary_local', 'salary_currency']\n",
    "\n",
    "# Check for other potential columns to drop (e.g., if they are mostly empty)\n",
    "# df_cleaned.isnull().sum() / len(df_cleaned) # <-- Run this to check % missing\n",
    "\n",
    "# Perform the drop\n",
    "existing_cols_to_drop = [col for col in cols_to_drop if col in df_cleaned.columns]\n",
    "df_cleaned.drop(columns=existing_cols_to_drop, inplace=True)\n",
    "\n",
    "print(f\"Dropped columns: {existing_cols_to_drop}\")\n",
    "print(f\"DataFrame shape after drops: {df_cleaned.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c3bdb706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicates found for job_id.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check for duplicates based on job_id\n",
    "duplicate_count = df_cleaned.duplicated(subset=['job_id']).sum()\n",
    "\n",
    "if duplicate_count > 0:\n",
    "    print(f\"Found {duplicate_count} duplicate job_id entries.\")\n",
    "else:\n",
    "    print(\"No duplicates found for job_id.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ae518c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with missing salary_usd: 0\n"
     ]
    }
   ],
   "source": [
    "# Check for missing salary_usd values\n",
    "missing_salary_count = df_cleaned['salary_usd'].isna().sum()\n",
    "print(f\"Rows with missing salary_usd: {missing_salary_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b3188acb-734a-4758-9333-6f8de4621474",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Data Type Conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "2c983466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "posting_date: 0 invalid date entries\n",
      "application_deadline: 0 invalid date entries\n",
      "years_experience: 0 invalid numeric entries\n",
      "job_description_length: 0 invalid numeric entries\n",
      "benefits_score: 0 invalid numeric entries\n"
     ]
    }
   ],
   "source": [
    "# 5. Checking for invalid dates and numeric values\n",
    "\n",
    "# Check for invalid date formats\n",
    "for dcol in ['posting_date', 'application_deadline']:\n",
    "    if dcol in df_cleaned.columns:\n",
    "        temp = pd.to_datetime(df_cleaned[dcol], errors='coerce')\n",
    "        invalid_dates = temp.isna().sum()\n",
    "        print(f\"{dcol}: {invalid_dates} invalid date entries\")\n",
    "\n",
    "# Check for invalid numeric values\n",
    "for ncol in ['years_experience', 'job_description_length', 'benefits_score']:\n",
    "    if ncol in df_cleaned.columns:\n",
    "        temp = pd.to_numeric(df_cleaned[ncol], errors='coerce')\n",
    "        invalid_numeric = temp.isna().sum()\n",
    "        print(f\"{ncol}: {invalid_numeric} invalid numeric entries\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e08d38",
   "metadata": {},
   "source": [
    "ddkodkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5c373a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map acronyms to clear, full text\n",
    "if 'experience_level' in df_cleaned.columns:\n",
    "    exp_map = {'EN': 'Entry-Level', 'MI': 'Mid-Level', 'SE': 'Senior-Level', 'EX': 'Executive'}\n",
    "    df_cleaned['experience_level'] = df_cleaned['experience_level'].map(exp_map).fillna(df_cleaned['experience_level'])\n",
    "\n",
    "if 'company_size' in df_cleaned.columns:\n",
    "    size_map = {'S': 'Small (<50)', 'M': 'Medium (50-250)', 'L': 'Large (>250)'}\n",
    "    df_cleaned['company_size'] = df_cleaned['company_size'].map(size_map).fillna(df_cleaned['company_size'])\n",
    "\n",
    "if 'employment_type' in df_cleaned.columns:\n",
    "    emp_map = {'FT': 'Full-Time', 'PT': 'Part-Time', 'CT': 'Contract', 'FL': 'Freelance'}\n",
    "    df_cleaned['employment_type'] = df_cleaned['employment_type'].map(emp_map).fillna(df_cleaned['employment_type'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "bdd70e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized 'experience_level', 'company_size', 'employment_type', and created 'remote_type'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>salary_usd</th>\n",
       "      <th>salary_currency</th>\n",
       "      <th>experience_level</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>company_location</th>\n",
       "      <th>company_size</th>\n",
       "      <th>employee_residence</th>\n",
       "      <th>remote_ratio</th>\n",
       "      <th>required_skills</th>\n",
       "      <th>education_required</th>\n",
       "      <th>years_experience</th>\n",
       "      <th>industry</th>\n",
       "      <th>posting_date</th>\n",
       "      <th>application_deadline</th>\n",
       "      <th>job_description_length</th>\n",
       "      <th>benefits_score</th>\n",
       "      <th>company_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AI00001</td>\n",
       "      <td>AI Research Scientist</td>\n",
       "      <td>90376</td>\n",
       "      <td>USD</td>\n",
       "      <td>SE</td>\n",
       "      <td>CT</td>\n",
       "      <td>China</td>\n",
       "      <td>M</td>\n",
       "      <td>China</td>\n",
       "      <td>50</td>\n",
       "      <td>Tableau, PyTorch, Kubernetes, Linux, NLP</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>9</td>\n",
       "      <td>Automotive</td>\n",
       "      <td>2024-10-18</td>\n",
       "      <td>2024-11-07</td>\n",
       "      <td>1076</td>\n",
       "      <td>5.9</td>\n",
       "      <td>Smart Analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AI00002</td>\n",
       "      <td>AI Software Engineer</td>\n",
       "      <td>61895</td>\n",
       "      <td>USD</td>\n",
       "      <td>EN</td>\n",
       "      <td>CT</td>\n",
       "      <td>Canada</td>\n",
       "      <td>M</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>100</td>\n",
       "      <td>Deep Learning, AWS, Mathematics, Python, Docker</td>\n",
       "      <td>Master</td>\n",
       "      <td>1</td>\n",
       "      <td>Media</td>\n",
       "      <td>2024-11-20</td>\n",
       "      <td>2025-01-11</td>\n",
       "      <td>1268</td>\n",
       "      <td>5.2</td>\n",
       "      <td>TechCorp Inc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AI00003</td>\n",
       "      <td>AI Specialist</td>\n",
       "      <td>152626</td>\n",
       "      <td>USD</td>\n",
       "      <td>MI</td>\n",
       "      <td>FL</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>L</td>\n",
       "      <td>South Korea</td>\n",
       "      <td>0</td>\n",
       "      <td>Kubernetes, Deep Learning, Java, Hadoop, NLP</td>\n",
       "      <td>Associate</td>\n",
       "      <td>2</td>\n",
       "      <td>Education</td>\n",
       "      <td>2025-03-18</td>\n",
       "      <td>2025-04-07</td>\n",
       "      <td>1974</td>\n",
       "      <td>9.4</td>\n",
       "      <td>Autonomous Tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AI00004</td>\n",
       "      <td>NLP Engineer</td>\n",
       "      <td>80215</td>\n",
       "      <td>USD</td>\n",
       "      <td>SE</td>\n",
       "      <td>FL</td>\n",
       "      <td>India</td>\n",
       "      <td>M</td>\n",
       "      <td>India</td>\n",
       "      <td>50</td>\n",
       "      <td>Scala, SQL, Linux, Python</td>\n",
       "      <td>PhD</td>\n",
       "      <td>7</td>\n",
       "      <td>Consulting</td>\n",
       "      <td>2024-12-23</td>\n",
       "      <td>2025-02-24</td>\n",
       "      <td>1345</td>\n",
       "      <td>8.6</td>\n",
       "      <td>Future Systems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AI00005</td>\n",
       "      <td>AI Consultant</td>\n",
       "      <td>54624</td>\n",
       "      <td>EUR</td>\n",
       "      <td>EN</td>\n",
       "      <td>PT</td>\n",
       "      <td>France</td>\n",
       "      <td>S</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>100</td>\n",
       "      <td>MLOps, Java, Tableau, Python</td>\n",
       "      <td>Master</td>\n",
       "      <td>0</td>\n",
       "      <td>Media</td>\n",
       "      <td>2025-04-15</td>\n",
       "      <td>2025-06-23</td>\n",
       "      <td>1989</td>\n",
       "      <td>6.6</td>\n",
       "      <td>Advanced Robotics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    job_id              job_title  salary_usd salary_currency  \\\n",
       "0  AI00001  AI Research Scientist       90376             USD   \n",
       "1  AI00002   AI Software Engineer       61895             USD   \n",
       "2  AI00003          AI Specialist      152626             USD   \n",
       "3  AI00004           NLP Engineer       80215             USD   \n",
       "4  AI00005          AI Consultant       54624             EUR   \n",
       "\n",
       "  experience_level employment_type company_location company_size  \\\n",
       "0               SE              CT            China            M   \n",
       "1               EN              CT           Canada            M   \n",
       "2               MI              FL      Switzerland            L   \n",
       "3               SE              FL            India            M   \n",
       "4               EN              PT           France            S   \n",
       "\n",
       "  employee_residence  remote_ratio  \\\n",
       "0              China            50   \n",
       "1            Ireland           100   \n",
       "2        South Korea             0   \n",
       "3              India            50   \n",
       "4          Singapore           100   \n",
       "\n",
       "                                   required_skills education_required  \\\n",
       "0         Tableau, PyTorch, Kubernetes, Linux, NLP           Bachelor   \n",
       "1  Deep Learning, AWS, Mathematics, Python, Docker             Master   \n",
       "2     Kubernetes, Deep Learning, Java, Hadoop, NLP          Associate   \n",
       "3                        Scala, SQL, Linux, Python                PhD   \n",
       "4                     MLOps, Java, Tableau, Python             Master   \n",
       "\n",
       "   years_experience    industry posting_date application_deadline  \\\n",
       "0                 9  Automotive   2024-10-18           2024-11-07   \n",
       "1                 1       Media   2024-11-20           2025-01-11   \n",
       "2                 2   Education   2025-03-18           2025-04-07   \n",
       "3                 7  Consulting   2024-12-23           2025-02-24   \n",
       "4                 0       Media   2025-04-15           2025-06-23   \n",
       "\n",
       "   job_description_length  benefits_score       company_name  \n",
       "0                    1076             5.9    Smart Analytics  \n",
       "1                    1268             5.2       TechCorp Inc  \n",
       "2                    1974             9.4    Autonomous Tech  \n",
       "3                    1345             8.6     Future Systems  \n",
       "4                    1989             6.6  Advanced Robotics  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Create remote_type from remote_ratio\n",
    "def remote_type_from_ratio(x):\n",
    "    if pd.isna(x): return 'Unknown'\n",
    "    if x == 0: return 'Onsite'\n",
    "    if x == 100: return 'Fully Remote'\n",
    "    if 0 < x < 100: return 'Hybrid'\n",
    "    return 'Unknown'\n",
    "\n",
    "if 'remote_ratio' in df_cleaned.columns:\n",
    "    df_cleaned['remote_type'] = df_cleaned['remote_ratio'].apply(remote_type_from_ratio)\n",
    "\n",
    "print(\"Standardized 'experience_level', 'company_size', 'employment_type', and created 'remote_type'.\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d07431e0-3a34-43f6-89e7-54c7a07872d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7. Feature Engineering: Skills Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b44712c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 'skills_list' and 'skills_count' features.\n",
      "                                   required_skills  \\\n",
      "0         Tableau, PyTorch, Kubernetes, Linux, NLP   \n",
      "1  Deep Learning, AWS, Mathematics, Python, Docker   \n",
      "2     Kubernetes, Deep Learning, Java, Hadoop, NLP   \n",
      "3                        Scala, SQL, Linux, Python   \n",
      "4                     MLOps, Java, Tableau, Python   \n",
      "\n",
      "                                         skills_list  skills_count  \n",
      "0         [tableau, pytorch, kubernetes, linux, nlp]             5  \n",
      "1  [deep learning, aws, mathematics, python, docker]             5  \n",
      "2     [kubernetes, deep learning, java, hadoop, nlp]             5  \n",
      "3                        [scala, sql, linux, python]             4  \n",
      "4                     [mlops, java, tableau, python]             4  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def parse_skills(text):\n",
    "    if pd.isna(text):\n",
    "        return []\n",
    "    # Split on common delimiters: comma, semicolon, pipe, newline\n",
    "    parts = re.split(r'[;,|\\n]+', str(text))\n",
    "    # Clean up whitespace, lowercase, and remove empty strings\n",
    "    skills = [p.strip().lower() for p in parts if p.strip()]\n",
    "    # Return unique skills\n",
    "    return list(dict.fromkeys(skills)) # Fast way to get unique list preserving order\n",
    "\n",
    "if 'required_skills' in df_cleaned.columns:\n",
    "    df_cleaned['skills_list'] = df_cleaned['required_skills'].apply(parse_skills)\n",
    "    df_cleaned['skills_count'] = df_cleaned['skills_list'].apply(len)\n",
    "    print(\"Created 'skills_list' and 'skills_count' features.\")\n",
    "else:\n",
    "    print(\"Warning: 'required_skills' column not found. Skipping skill processing.\")\n",
    "\n",
    "# Display sample of engineered features\n",
    "print(df_cleaned[['required_skills', 'skills_list', 'skills_count']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4ffa6126-08de-4303-a65d-babac7567f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8. Numerical Imputation & Outlier Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e8366fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['posting_date'] = pd.to_datetime(df['posting_date'])\n",
    "df['application_deadline'] = pd.to_datetime(df['application_deadline'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4c252f2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        20\n",
       "1        52\n",
       "2        20\n",
       "3        63\n",
       "4        69\n",
       "         ..\n",
       "14995    47\n",
       "14996    14\n",
       "14997    44\n",
       "14998    32\n",
       "14999    23\n",
       "Name: application_duration, Length: 15000, dtype: int64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['application_duration'] = (df['application_deadline'] - df['posting_date']).dt.days\n",
    "df['application_duration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "049e7743-4162-4edb-a7f7-86bc4f657135",
   "metadata": {},
   "outputs": [],
   "source": [
    "#9. Save Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "75201a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned global data to: data\\processed\\new_jobs_global.csv\n",
      "Final dataset shape: (15000, 21)\n"
     ]
    }
   ],
   "source": [
    "OUT_DIR = Path('data/processed')\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "clean_path = OUT_DIR / 'new_jobs_global.csv'\n",
    "\n",
    "df_cleaned.to_csv(clean_path, index=False)\n",
    "\n",
    "print(f\"Saved cleaned global data to: {clean_path}\")\n",
    "print(f\"Final dataset shape: {df_cleaned.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b7ca4dd0-f878-4c81-89e2-64dcd4f1732a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10. Initial Feature Importance Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca7c277",
   "metadata": {},
   "source": [
    "## Next steps & notes\n",
    "- Review `data/processed/cleaned_jobs_usa.parquet` and `data/processed/feature_importance.csv`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a48b392-6873-49d4-9f18-d40b2fc0f886",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dmml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
